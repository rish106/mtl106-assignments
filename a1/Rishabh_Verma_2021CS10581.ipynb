{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTL106 Assignment 1\n",
    "\n",
    "My entry number is 2021CS10581 so the strengths of my warriors are 5, 8 and 1.\n",
    "\n",
    "In Python, `random.random()` returns a float in [0, 1), so to check if an event with probability $p$ has occurred, it can be checked if `random.random()` $< p$ (without equality, otherwise impossible events with probability 0 will occur)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "my_warriors = [5, 8, 1]\n",
    "alice_warriors = [3, 4, 6, 7]\n",
    "\n",
    "\n",
    "def win_probability(my_pick, alice_pick):\n",
    "    return my_pick / (my_pick + alice_pick)\n",
    "\n",
    "\n",
    "def single_game(pick_strategy):\n",
    "    global my_warriors, alice_warriors\n",
    "    curr_my_warriors = my_warriors.copy()\n",
    "    curr_alice_warriors = alice_warriors.copy()\n",
    "\n",
    "    while curr_my_warriors and curr_alice_warriors:\n",
    "        alice_pick = random.choice(curr_alice_warriors)\n",
    "        my_pick = pick_strategy(curr_my_warriors)\n",
    "        prob_win = win_probability(my_pick, alice_pick)\n",
    "\n",
    "        curr_my_warriors.remove(my_pick)\n",
    "        curr_alice_warriors.remove(alice_pick)\n",
    "\n",
    "        if random.random() < prob_win:\n",
    "            curr_my_warriors.append(my_pick + alice_pick)\n",
    "        else:\n",
    "            curr_alice_warriors.append(my_pick + alice_pick)\n",
    "\n",
    "    return len(curr_my_warriors) > 0\n",
    "\n",
    "\n",
    "def simulate_games(pick_strategy):\n",
    "    wins = 0\n",
    "    num_iterations = 100000\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        wins += single_game(pick_strategy)\n",
    "\n",
    "    return wins / num_iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change strengths of warriors here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_warriors = [5, 8, 1]\n",
    "alice_warriors = [3, 4, 6, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Max strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_strategy(my_warriors):\n",
    "    return max(my_warriors)\n",
    "\n",
    "max_strat_probability = simulate_games(max_strategy)\n",
    "print(\"With max strategy\", max_strat_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Min strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_strategy(my_warriors):\n",
    "    return min(my_warriors)\n",
    "\n",
    "min_strat_probability = simulate_games(min_strategy)\n",
    "print(\"With min strategy\", min_strat_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Expected Gain\n",
    "\n",
    "Let strength gained upon winning be denoted by $S_{gained}$ and strength lost upon losing be denoted by $S_{lost}$.\n",
    "\n",
    "$E[gain] = P_{win} \\times S_{gained} - P_{loss} \\times S_{lost}$\n",
    "\n",
    "$Pick_{Alice} = S_{gained} = x$\n",
    "\n",
    "$Pick_{Me} = S_{lost} = y$\n",
    "\n",
    "$P_{win} = \\frac{y}{x + y}$\n",
    "\n",
    "$P_{loss} = \\frac{x}{x + y}$\n",
    "\n",
    "$\\implies E[gain] = (\\frac{y}{x + y} \\times x) - (\\frac{x}{x + y} \\times y)$\n",
    "\n",
    "$\\implies E[gain] = \\frac{y \\times x}{x + y} - \\frac{x \\times y}{x + y}$\n",
    "\n",
    "$\\implies E[gain] = 0$\n",
    "\n",
    "Yes, every match is fair.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Optimal strategy and Probability of Winning\n",
    "\n",
    "Let total strength after the simulation of a match be denoted by $S_{total}$ and the sum of initial strengths be denoted by $S_{initial}$.\n",
    "\n",
    "$S_{total} = S_{initial} + \\sum_{i \\geq 1}gain_i$\n",
    "\n",
    "$\\because E[gain_i] = 0 \\hspace{2mm} \\forall \\hspace{2mm} i \\geq 1$\n",
    "\n",
    "$\\therefore \\sum_{i \\ge 1}E[gain_i] = 0$\n",
    "\n",
    "$\\implies E[S_{total}] = S_{initial}$\n",
    "\n",
    "Let the sum of strengths of my warriors be denoted by $T_{Me}$(equal to $S_{initial}$) and the sum of strengths of Alice's warriors be denoted by $T_{Alice}$. Let the theoretical value of probability of winning be $p$.\n",
    "\n",
    "$\\implies$ With probability $p$, $\\hspace{1mm} S_{total} = T_{Me} + T_{Alice}$\n",
    "\n",
    "and with probability $1 - p$, $\\hspace{1mm} S_{total} = 0$\n",
    "\n",
    "$\\implies E[S_{total}] = p \\times (T_{Me} + T_{Alice}) + (1 - p) \\times 0$\n",
    "\n",
    "$\\implies T_{Me} = p \\times (T_{Me} + T_{Alice})$\n",
    "\n",
    "$\\therefore p = \\frac{T_{Me}}{T_{Me} + T_{Alice}}$\n",
    "\n",
    "In this case, $T_{Me} = 5 + 8 + 1 = 14 \\hspace{1mm}$ and $\\hspace{1mm} T_{Alice} = 3 + 4 + 6 + 7 = 20$\n",
    "\n",
    "$\\therefore p = \\frac{14}{14 + 20} = \\frac{14}{34} \\approx 0.411765$\n",
    "\n",
    "Since the expected gain is $0$, no matter what strategy is used to pick, the probability given by Monte Carlo simulation with $10^5$ iterations will always tend to the theoretical value $p$.\n",
    "\n",
    "Hence, the probability of winning with optimal strategy is the same as the probability of winning with any strategy.\n",
    "\n",
    "$p^* = p$\n",
    "\n",
    "$p^* \\approx 0.411765$\n",
    "\n",
    "It can be verified by using some *weird* strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Random strategy\n",
    "\n",
    "Pick a warrior randomly from my warriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_strategy(my_warriors):\n",
    "    return random.choice(my_warriors)\n",
    "\n",
    "random_strat_probability = simulate_games(random_strategy)\n",
    "print(\"With random strategy\", random_strat_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Partial Min Max strategy\n",
    "\n",
    "Pick minimum strength warrior with probability 0.5 and maximum strength warrior otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_min_max_strat(my_warriors):\n",
    "    if random.random() < 0.5:\n",
    "        return min(my_warriors)\n",
    "    else:\n",
    "        return max(my_warriors)\n",
    "\n",
    "partial_min_max_strat_probability = simulate_games(partial_min_max_strat)\n",
    "print(\"With partial min max strategy\", partial_min_max_strat_probability)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
